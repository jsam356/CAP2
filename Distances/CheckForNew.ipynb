{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is used when adding new samples to the analyses done in the Scatterplot notebook. Here we check which samples from the downloaded data have already been added and which not. It also helps to determine which papers are associated to the new samples.**\n",
    "\n",
    "For now this notebook is geared for loading the second batch of data. When the third one and subsequent ones arrivea it will be further modified accordingly if needed. An alternative is simply to combine all previous Proj_UID files prior to the latest batch into Proj_UID.csv and run the same code with the required modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for New Samples after Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first batch of samples (original samples) were processed and matched to bioprojects using the ProjectMatch\n",
    "#notebook in the Match folder.\n",
    "\n",
    "#Proj_UID is a csv file with the sample ids and their associated bioproject identifier (beggining with PJRNA).\n",
    "Orig=open(\"Proj_UID.csv\",\"r\")\n",
    "\n",
    "#Here we simply load that first batch and get the sample ids. We save them in OrigSample.\n",
    "OrigSample=[]\n",
    "for line in Orig:\n",
    "    OrigSample.append(line.strip(\"\\n\").split(\";\")[0])\n",
    "    \n",
    "Orig.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we open the Mash distance tab file with all pairwise distances between all samples (regardless of the batch\n",
    "#of data they are in) .\n",
    "New=open(\"NewDistances.tab\",\"r\", encoding=\"utf-8\")\n",
    "\n",
    "#From the file we get all sample ids which had a match sketch (and therefore have Mash distances with the other \n",
    "#samples).\n",
    "NewSet=[]\n",
    "for line in New:\n",
    "#We parse the file and get sample ids.\n",
    "    try:\n",
    "        sample=line.strip(\"\\n\").split(\"\\t\")[0].split(\"_\")[0].split(\"/\")[1]\n",
    "#For now we save all sample ids in NewSet.\n",
    "        if sample not in NewSet:\n",
    "            NewSet.append(sample)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we get the difference between NewSeq and OrigSample. Sample ids present in the former but not the later\n",
    "#are new samples (belong to the latest batch) and hence need to be processed before they can be analyzed.\n",
    "NewSamples=list(set(NewSet)-set(OrigSample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll need to look for the bioproject associated to the new sample ids using Entrez Direct. In both\n",
    "#cases we'll need a list of the new sample ids. We generate a text file with those ids, NewSampleIds, here.\n",
    "NewS=open(\"NewSampleIds.txt\",\"w\")\n",
    "\n",
    "for i in NewSamples:\n",
    "    NewS.write(i+\"\\n\")\n",
    "NewS.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Associate bioproject to new samples after Entrez download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After using Entrez direct to download the reocrds of all samples, we can move on to associate the bioproject (which is\n",
    "#within the record) to the samples. First we load the new sample ids (the ones form the latest batch).\n",
    "NewS=open(\"NewSampleIds.txt\",\"r\")\n",
    "\n",
    "NewSamples=[]\n",
    "for line in NewS:\n",
    "    NewSamples.append(line.strip(\"\\n\"))\n",
    "NewS.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The idea here is as follows: the run record does not have the sample id, but we downloaded the records in the same \n",
    "#order as the samples are placed in NewSampleIds, so we simply need to match the first bioproject identifier from the\n",
    "#first record in NewSraRunInfo.csv (output from Entrez Direct to the first sample, the second to the second, and so on.\n",
    "NewProj=open(\"NewSraRunInfo.csv\",\"r\")\n",
    "\n",
    "#We check the lines of NewSraRunInfo and extract the bioproject using a combination of \"PJRNA\" and commas as data\n",
    "#delimiters. We save the ordered list of bioprojects in NProj.\n",
    "NProj=[]\n",
    "for line in NewProj:\n",
    "    if \"Run,ReleaseDate\" in line:\n",
    "        continue\n",
    "    line=line.strip(\"\\n\").split(\"PRJNA\")[1].split(\",\")[0]\n",
    "    NProj.append(\"PRJNA\"+line)\n",
    "NewProj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we can generate a Proj_UID csv file for the new samples. We do that there using both NewSamples and \n",
    "#NProj. \n",
    "Out=open(\"Proj_UIDBatch2.csv\",\"w\")\n",
    "\n",
    "for (ID,proj)in zip(NewSamples,NProj):\n",
    "    Out.write(ID+\";\"+proj+\"\\n\")\n",
    "    \n",
    "Out.close()\n",
    "\n",
    "#It's ideal to check the output file as some bioprojects are not adequately parsed from NewSraRunInfo.csv (will try to \n",
    "#correct that later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
