{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is used when adding new samples to the analyses done in the Scatterplot notebook. Here we check which samples from the downloaded data have already been added and which not. It also helps to determine which bioprojects are associated to the new samples and which SRR (run) identifiers.**\n",
    "\n",
    "For now this notebook is geared for loading the second batch of data. When the third one and subsequent ones arrivea it will be further modified accordingly if needed. An alternative is simply to combine all previous Proj_UID files prior to the latest batch into Proj_UID.csv and run the same code with the required modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for New Samples after Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first batch of samples (original samples) were processed and matched to bioprojects using the ProjectMatch\n",
    "#notebook in the Match folder.\n",
    "\n",
    "#Proj_UID is a csv file with the sample ids and their associated bioproject identifier (beggining with PJRNA).\n",
    "Orig=open(\"Proj_UID.csv\",\"r\")\n",
    "\n",
    "#Here we simply load that first batch and get the sample ids. We save them in OrigSample.\n",
    "OrigSample=[]\n",
    "for line in Orig:\n",
    "    OrigSample.append(line.strip(\"\\n\").split(\";\")[0])\n",
    "    \n",
    "Orig.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we open the Mash distance tab file with all pairwise distances between all samples (regardless of the batch\n",
    "#of data they are in) .\n",
    "New=open(\"NewDistances.tab\",\"r\", encoding=\"utf-8\")\n",
    "\n",
    "#From the file we get all sample ids which had a match sketch (and therefore have Mash distances with the other \n",
    "#samples).\n",
    "NewSet=[]\n",
    "for line in New:\n",
    "#We parse the file and get sample ids.\n",
    "    try:\n",
    "        sample=line.strip(\"\\n\").split(\"\\t\")[0].split(\"_\")[0].split(\"/\")[1]\n",
    "#For now we save all sample ids in NewSet.\n",
    "        if sample not in NewSet:\n",
    "            NewSet.append(sample)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we get the difference between NewSeq and OrigSample. Sample ids present in the former but not the later\n",
    "#are new samples (belong to the latest batch) and hence need to be processed before they can be analyzed.\n",
    "NewSamples=list(set(NewSet)-set(OrigSample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll need to look for the bioproject associated to the new sample ids using Entrez Direct. In both\n",
    "#cases we'll need a list of the new sample ids. We generate a text file with those ids, NewSampleIds, here.\n",
    "NewS=open(\"NewSampleIds.txt\",\"w\")\n",
    "\n",
    "for i in NewSamples:\n",
    "    NewS.write(i+\"\\n\")\n",
    "NewS.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Associate bioproject to new samples after Entrez download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After using Entrez direct to download the reocrds of all samples, we can move on to associate the bioproject (which is\n",
    "#within the record) and the SRR id to the samples. First we load the new sample ids (the ones form the latest batch).\n",
    "NewS=open(\"NewSampleIds.txt\",\"r\")\n",
    "\n",
    "NewSamples=[]\n",
    "for line in NewS:\n",
    "    NewSamples.append(line.strip(\"\\n\"))\n",
    "NewS.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The idea here is as follows: the run record does not have the sample id, but we downloaded the records in the same \n",
    "#order as the samples are placed in NewSampleIds, so we simply need to match the first bioproject identifier from the\n",
    "#first record in NewSraRunInfo.csv (output from Entrez Direct to the first sample, the second to the second, and so on,\n",
    "#and the same for the run ids.\n",
    "NewProj=open(\"NewSraRunInfo.csv\",\"r\")\n",
    "\n",
    "#We check the lines of NewSraRunInfo and extract the bioproject using a combination of \"PJRNA\" and commas as data\n",
    "#delimiters. We save the ordered list of bioprojects in NProj.\n",
    "\n",
    "#We do a parallel thing with the run ids, noting that they are located in the first column of the csv. We save them\n",
    "#in SRRList\n",
    "NProj=[]\n",
    "SRRList=[]\n",
    "for line in NewProj:\n",
    "    if \"Run,ReleaseDate\" in line:\n",
    "        continue\n",
    "    newProj=line.strip(\"\\n\").split(\"PRJNA\")[1].split(\",\")[0]\n",
    "    NProj.append(\"PRJNA\"+newProj)\n",
    "    SRRList.append(line.strip(\"\\n\").split(\",\")[0])\n",
    "NewProj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally we can generate a Proj_UID csv file for the new samples. We do that there using NewSamples, SRRList, and\n",
    "#NProj. \n",
    "Out=open(\"Proj_UIDBatch2.csv\",\"w\")\n",
    "\n",
    "for (ID,proj,SRR)in zip(NewSamples,NProj,SRRList):\n",
    "    Out.write(ID+\";\"+proj+\";\"+SRR+\"\\n\")\n",
    "    \n",
    "Out.close()\n",
    "\n",
    "#It's ideal to check the output file as some bioprojects are not adequately parsed from NewSraRunInfo.csv (will try to \n",
    "#correct that later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Associate SRR to samples of First Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something that came up after setting up the first two subsections was to associate the SRR (run) identifier of each sample to sample id itself. As such, this needs to be done for the original set of data only as the second set could be modified above to include it.\n",
    "\n",
    "We do that here and add the infromation to the Proj_UID file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The methodology is simply to load Proj_UID, and save the information. \n",
    "NewS=open(\"Proj_UID.csv\",\"r\")\n",
    "\n",
    "info=[]\n",
    "for line in NewS:\n",
    "    info.append(line.strip(\"\\n\"))\n",
    "NewS.close()\n",
    "\n",
    "#Then we load the ordered RunInfo list and save the SRRs.\n",
    "                \n",
    "NewInfo=open(\"OldIDInfo.csv\",\"r\")\n",
    "\n",
    "SRRs=[]\n",
    "for line in NewInfo:\n",
    "    if \"Run\" in line:\n",
    "        continue\n",
    "    SRRs.append(line.strip(\"\\n\").split(\",\")[0])\n",
    "NewInfo.close()    \n",
    "\n",
    "#Finally we save everything in Proj_UID.\n",
    "\n",
    "WithSRR=open(\"Proj_UID.csv\",\"w\")\n",
    "\n",
    "for i in range(len(info)):\n",
    "    WithSRR.write(info[i]+\";\"+SRRs[i]+\"\\n\")\n",
    "\n",
    "WithSRR.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
